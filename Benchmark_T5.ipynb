{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22150ce8-3755-4ed7-94f0-aafc8e7f6ada",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.40.2-py3-none-any.whl (9.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.19.3\n",
      "  Downloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 KB\u001b[0m \u001b[31m111.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Collecting tokenizers<0.20,>=0.19\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2024.4.28-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (774 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.1/774.1 KB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
      "Collecting numpy>=1.17\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.1)\n",
      "Installing collected packages: safetensors, regex, numpy, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.23.0 numpy-1.26.4 regex-2024.4.28 safetensors-0.4.3 tokenizers-0.19.1 transformers-4.40.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4c4de1-3dfa-4d23-a531-be2c7b420b78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "180663ab-5452-4400-b811-c3e1a39f4828",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-30 03:01:48 pynccl.py:58] Loading nccl from library /root/.config/vllm/nccl/cu12/libnccl.so.2.18.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 03:01:48,774\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Model - Avg Latency: 1.031s, Throughput: 0.97 req/s, Time to First Token: 0.847s\n",
      "Cached Model - Avg Latency: 0.002s, Throughput: 459.32 req/s, Time to First Token: 0.002s\n",
      "Optimized Model - Avg Latency: 0.002s, Throughput: 437.17 req/s, Time to First Token: 0.002s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from transformers import T5Tokenizer\n",
    "from vllm.model_executor.models import T5ForVLLM, T5ForVLLMWithCache, T5ForVLLMWithDistributedCache\n",
    "\n",
    "# Define model and tokenizer paths\n",
    "model_dir = '/data/data/vllm/vllm/model_executor/models/t5-small-model/'\n",
    "tokenizer_dir = '/data/data/vllm/vllm/model_executor/models/t5-small-tokenizer/'\n",
    "\n",
    "# Initialize tokenizers and models\n",
    "tokenizer = T5Tokenizer.from_pretrained(tokenizer_dir)\n",
    "basic_model = T5ForVLLM(model_dir, tokenizer_dir)\n",
    "cached_model = T5ForVLLMWithCache(model_dir, tokenizer_dir)\n",
    "optimized_model = T5ForVLLMWithDistributedCache(model_dir, tokenizer_dir)\n",
    "\n",
    "# Input text for testing\n",
    "input_text = \"Translate English to French: Hi How are you, what's happening, tell me something new?\"\n",
    "\n",
    "# Function to benchmark a model\n",
    "def benchmark_model(model, text, iterations=10):\n",
    "    # Warm up model\n",
    "    for _ in range(2):\n",
    "        model.generate(text)\n",
    "\n",
    "    # Measure latency and time to first token\n",
    "    start_time = time.time()\n",
    "    for _ in range(iterations):\n",
    "        start = time.time()\n",
    "        model.generate(text)\n",
    "        first_token_time = time.time() - start  # This simplifies first token time to full generation time\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    avg_latency = total_time / iterations\n",
    "    avg_first_token_time = first_token_time  # Simplistic assumption\n",
    "\n",
    "    # Throughput calculation\n",
    "    throughput = iterations / total_time\n",
    "\n",
    "    return avg_latency, throughput, avg_first_token_time\n",
    "\n",
    "# Run benchmarks\n",
    "basic_latency, basic_throughput, basic_first_token = benchmark_model(basic_model, input_text)\n",
    "cached_latency, cached_throughput, cached_first_token = benchmark_model(cached_model, input_text)\n",
    "optimized_latency, optimized_throughput, optimized_first_token = benchmark_model(optimized_model, input_text)\n",
    "\n",
    "# Print results\n",
    "print(\"Basic Model - Avg Latency: {:.3f}s, Throughput: {:.2f} req/s, Time to First Token: {:.3f}s\".format(basic_latency, basic_throughput, basic_first_token))\n",
    "print(\"Cached Model - Avg Latency: {:.3f}s, Throughput: {:.2f} req/s, Time to First Token: {:.3f}s\".format(cached_latency, cached_throughput, cached_first_token))\n",
    "print(\"Optimized Model - Avg Latency: {:.3f}s, Throughput: {:.2f} req/s, Time to First Token: {:.3f}s\".format(optimized_latency, optimized_throughput, optimized_first_token))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9a7093-31d8-4adc-ac55-16a8017d7fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d3467a-ae01-4b7c-a233-6a56d743ca95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4a41cb5-7b57-4ba4-9819-7330f206a2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-30 06:44:28 pynccl.py:58] Loading nccl from library /root/.config/vllm/nccl/cu12/libnccl.so.2.18.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 06:44:29,334\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Type: exact_match, Cache Status: Hit, Time Taken: 0.00s, Output: ['Bonjour, comment êtes-vous?']...\n",
      "Prompt Type: case_change, Cache Status: Miss, Time Taken: 0.93s, Output: ['Hallo, comment êtes-vous?']...\n",
      "Prompt Type: punctuation_change, Cache Status: Miss, Time Taken: 0.31s, Output: ['Bonjour, comment êtes-vous!']...\n",
      "Prompt Type: whitespace_change, Cache Status: Hit, Time Taken: 0.00s, Output: ['Bonjour, comment êtes-vous?']...\n",
      "Prompt Type: minor_text_change, Cache Status: Miss, Time Taken: 0.27s, Output: ['Bonjour, comment faites-vous?']...\n",
      "Prompt Type: frequent_request, Cache Status: Miss, Time Taken: 0.31s, Output: ['Wie sieht das Wetter in Paris heute?']...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from transformers import T5Tokenizer\n",
    "from vllm.model_executor.models import T5ForVLLMWithDistributedCache\n",
    "\n",
    "# Define model and tokenizer paths\n",
    "# Define model and tokenizer paths\n",
    "model_dir = '/data/data/vllm/vllm/model_executor/models/t5-small-model/'\n",
    "tokenizer_dir = '/data/data/vllm/vllm/model_executor/models/t5-small-tokenizer/'\n",
    "\n",
    "# Initialize the tokenizer and model\n",
    "tokenizer = T5Tokenizer.from_pretrained(tokenizer_dir)\n",
    "model = T5ForVLLMWithDistributedCache(model_dir, tokenizer_dir)\n",
    "\n",
    "# List of prompts to test\n",
    "prompts = {\n",
    "    \"exact_match\": \"Translate English to French: Hello, how are you?\",\n",
    "    \"case_change\": \"translate english to french: hello, how are you?\",\n",
    "    \"punctuation_change\": \"Translate English to French: Hello, how are you!\",\n",
    "    \"whitespace_change\": \"Translate English to French: Hello, how are you? \",\n",
    "    \"minor_text_change\": \"Translate English to French: Hello, how are you doing?\",\n",
    "    \"frequent_request\": \"What is the weather like in Paris today?\"\n",
    "}\n",
    "\n",
    "# Function to test each prompt and measure caching impact\n",
    "def test_caching(model, prompts):\n",
    "    results = {}\n",
    "    for prompt_type, text in prompts.items():\n",
    "        start_time = time.time()\n",
    "        output, cache_hit = model.generate(text)  # Receive output and cache hit status\n",
    "        duration = time.time() - start_time\n",
    "\n",
    "        results[prompt_type] = {\n",
    "            \"duration\": duration,\n",
    "            \"cache_hit\": cache_hit,\n",
    "            \"output\": output\n",
    "        }\n",
    "    return results\n",
    "\n",
    "# Run the test\n",
    "results = test_caching(model, prompts)\n",
    "\n",
    "# Print results\n",
    "for prompt_type, info in results.items():\n",
    "    cache_status = \"Hit\" if info[\"cache_hit\"] else \"Miss\"\n",
    "    print(f\"Prompt Type: {prompt_type}, Cache Status: {cache_status}, Time Taken: {info['duration']:.2f}s, Output: {info['output'][:30]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07252799-6aef-4dfe-a84b-e6837490dfb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
